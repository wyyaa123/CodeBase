

<center class="half">
    <img src="./assets/èµ›é©¬å¨˜.gif" style="zoom:50%;"/>
</center>


## 2023å¹´8æœˆ16æ—¥

### ä¸€ã€è®­ç»ƒé›†

è¿™ä¸ªæ˜¯æœ€å¥½ç†è§£çš„ï¼Œç”¨æ¥è®­ç»ƒæ¨¡å‹å†…å‚æ•°çš„æ•°æ®é›†ï¼Œåˆ†ç±»å™¨ç›´æ¥æ ¹æ®è®­ç»ƒé›†æ¥è°ƒæ•´è‡ªèº«è·å¾—æ›´å¥½çš„åˆ†ç±»æ•ˆæœ

### äºŒã€éªŒè¯é›†

ç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ£€éªŒæ¨¡å‹çš„çŠ¶æ€ï¼Œæ”¶æ•›æƒ…å†µã€‚éªŒè¯é›†é€šå¸¸ç”¨äºè°ƒæ•´è¶…å‚æ•°ï¼Œæ ¹æ®å‡ ç»„æ¨¡å‹éªŒè¯é›†ä¸Šçš„è¡¨ç°å†³å®šå“ªç»„è¶…å‚æ•°æ‹¥æœ‰æœ€å¥½çš„æ€§èƒ½ã€‚

åŒæ—¶éªŒè¯é›†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿˜å¯ä»¥ç”¨æ¥ç›‘æ§æ¨¡å‹æ˜¯å¦å‘ç”Ÿè¿‡æ‹Ÿåˆï¼Œä¸€èˆ¬æ¥è¯´éªŒè¯é›†è¡¨ç°ç¨³å®šåï¼Œè‹¥ç»§ç»­è®­ç»ƒï¼Œè®­ç»ƒé›†è¡¨ç°è¿˜ä¼šç»§ç»­ä¸Šå‡ï¼Œä½†æ˜¯éªŒè¯é›†ä¼šå‡ºç°ä¸å‡åé™çš„æƒ…å†µï¼Œè¿™æ ·ä¸€èˆ¬å°±å‘ç”Ÿäº†è¿‡æ‹Ÿåˆã€‚æ‰€ä»¥éªŒè¯é›†ä¹Ÿç”¨æ¥åˆ¤æ–­ä½•æ—¶åœæ­¢è®­ç»ƒ

### ä¸‰ã€æµ‹è¯•é›†ğŸ˜

æµ‹è¯•é›†ç”¨æ¥è¯„ä»·æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼Œå³ä¹‹å‰æ¨¡å‹ä½¿ç”¨éªŒè¯é›†ç¡®å®šäº†è¶…å‚æ•°ï¼Œä½¿ç”¨è®­ç»ƒé›†è°ƒæ•´äº†å‚æ•°ï¼Œæœ€åä½¿ç”¨ä¸€ä¸ªä»æ²¡æœ‰è§è¿‡çš„æ•°æ®é›†æ¥åˆ¤æ–­è¿™ä¸ªæ¨¡å‹æ˜¯å¦Workã€‚

### å››ã€è®­ç»ƒè¯¯å·®ä¸æ³›åŒ–è¯¯å·®

æœºå™¨å­¦ä¹ åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šè¡¨ç°å‡ºçš„è¯¯å·®å«åšè®­ç»ƒè¯¯å·®ï¼Œåœ¨ä»»æ„ä¸€ä¸ªæµ‹è¯•æ•°æ®æ ·æœ¬ä¸Šçš„è¯¯å·®çš„æœŸæœ›å€¼å«åšæ³›åŒ–è¯¯å·®ã€‚

### äº”ã€æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆ

##### 	ä»€ä¹ˆæ˜¯æ¬ æ‹Ÿåˆï¼Ÿ

æ¬ æ‹Ÿåˆæ˜¯æŒ‡æ¨¡å‹ä¸èƒ½åœ¨è®­ç»ƒé›†ä¸Šè·å¾—è¶³å¤Ÿä½çš„è¯¯å·®ã€‚æ¢å¥æ¢è¯´ï¼Œå°±æ˜¯æ¨¡å‹å¤æ‚åº¦ä½ï¼Œæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šå°±è¡¨ç°å¾ˆå·®ï¼Œæ²¡æ³•å­¦ä¹ åˆ°æ•°æ®èƒŒåçš„è§„å¾‹ã€‚

##### 	å¦‚ä½•è§£å†³æ¬ æ‹Ÿåˆï¼Ÿ

æ¬ æ‹ŸåˆåŸºæœ¬ä¸Šéƒ½ä¼šå‘ç”Ÿåœ¨è®­ç»ƒåˆšå¼€å§‹çš„æ—¶å€™ï¼Œç»è¿‡ä¸æ–­è®­ç»ƒä¹‹åæ¬ æ‹Ÿåˆåº”è¯¥ä¸æ€ä¹ˆè€ƒè™‘äº†ã€‚ä½†æ˜¯å¦‚æœçœŸçš„è¿˜æ˜¯å­˜åœ¨çš„è¯ï¼Œå¯ä»¥é€šè¿‡**å¢åŠ ç½‘ç»œå¤æ‚åº¦**æˆ–è€…åœ¨æ¨¡å‹ä¸­**å¢åŠ ç‰¹å¾**ï¼Œè¿™äº›éƒ½æ˜¯å¾ˆå¥½è§£å†³æ¬ æ‹Ÿåˆçš„æ–¹æ³•ã€‚

##### 	ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆï¼Ÿ

è¿‡æ‹Ÿåˆæ˜¯æŒ‡è®­ç»ƒè¯¯å·®å’Œæµ‹è¯•è¯¯å·®ä¹‹é—´çš„å·®è·å¤ªå¤§ã€‚æ¢å¥æ¢è¯´ï¼Œå°±æ˜¯æ¨¡å‹å¤æ‚åº¦é«˜äºå®é™…é—®é¢˜ï¼Œ**æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°å¾ˆå¥½ï¼Œä½†åœ¨æµ‹è¯•é›†ä¸Šå´è¡¨ç°å¾ˆå·®**ã€‚æ¨¡å‹å¯¹è®­ç»ƒé›†"æ­»è®°ç¡¬èƒŒ"ï¼ˆè®°ä½äº†ä¸é€‚ç”¨äºæµ‹è¯•é›†çš„è®­ç»ƒé›†æ€§è´¨æˆ–ç‰¹ç‚¹ï¼‰ï¼Œæ²¡æœ‰ç†è§£æ•°æ®èƒŒåçš„è§„å¾‹ï¼Œ**æ³›åŒ–èƒ½åŠ›å·®**ã€‚

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="./assets/1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">æ¨¡å‹å®¹é‡ä¸æ‹Ÿåˆç¨‹åº¦ä¹‹é—´å…³ç³»</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="./assets/2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">æ¬ æ‹Ÿåˆä¸è¿‡æ‹Ÿåˆ</div>
</center>





è®­ç»ƒåˆšå¼€å§‹çš„æ—¶å€™ï¼Œæ¨¡å‹è¿˜åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­è®­ç»ƒè¯¯å·®å’Œæµ‹è¯•è¯¯å·®è¾ƒå¤§ï¼Œå¤„äºæ¬ æ‹ŸåˆåŒºåŸŸã€‚éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œè®­ç»ƒè¯¯å·®å’Œæµ‹è¯•è¯¯å·®éƒ½ä¸‹é™ã€‚åœ¨åˆ°è¾¾ä¸€ä¸ªä¸´ç•Œç‚¹ä¹‹åï¼Œè®­ç»ƒé›†çš„è¯¯å·®ä¸‹é™ï¼Œæµ‹è¯•é›†çš„è¯¯å·®å´ä¸Šå‡äº†ï¼Œè¿™ä¸ªæ—¶å€™å°±è¿›å…¥äº†è¿‡æ‹ŸåˆåŒºåŸŸâ€”â€”ç”±äºè®­ç»ƒå‡ºæ¥çš„ç½‘ç»œ**è¿‡åº¦æ‹Ÿåˆäº†è®­ç»ƒé›†**ï¼Œå¯¹è®­ç»ƒé›†ä»¥å¤–çš„æ•°æ®å´ä¸workã€‚

å¯ä»¥åœ¨æŸå¤±å‡½æ•°å¤„åŠ ä¸Šæ­£åˆ™åŒ–$L1$èŒƒæ•°æˆ–$L2$èŒƒæ•°.

## 2023å¹´8æœˆ17æ—¥

### ä¸€ã€ä¸ºä»€ä¹ˆéœ€è¦æ¿€æ´»å‡½æ•°ï¼Ÿ

å¦‚æœä¸ä½¿ç”¨æ¿€æ´»å‡½æ•°ï¼Œæˆ‘ä»¬çš„æ¯ä¸€å±‚è¾“å‡ºåªæ˜¯æ‰¿æ¥äº†ä¸Šä¸€å±‚è¾“å…¥å‡½æ•°çš„çº¿æ€§å˜æ¢ï¼Œæ— è®ºç¥ç»ç½‘ç»œæœ‰å¤šå°‘å±‚ï¼Œè¾“å‡ºéƒ½æ˜¯è¾“å…¥çš„çº¿æ€§ç»„åˆã€‚ å¦‚æœä½¿ç”¨çš„è¯ï¼Œ**æ¿€æ´»å‡½æ•°ç»™ç¥ç»å…ƒå¼•å…¥äº†éçº¿æ€§çš„å› ç´ ï¼Œä½¿å¾—ç¥ç»ç½‘ç»œå¯ä»¥é€¼è¿‘ä»»ä½•éçº¿æ€§å‡½æ•°ï¼Œè¿™æ ·ç¥ç»ç½‘ç»œå°±å¯ä»¥åº”ç”¨åˆ°éçº¿æ€§æ¨¡å‹ä¸­**ã€‚

## 2023å¹´8æœˆ18æ—¥

### ä¸€ã€ ä»€ä¹ˆæ˜¯è§‚æµ‹è¯¯å·®

[å®éªŒ](https://zh.wikipedia.org/wiki/å®éªŒ)[ç§‘å­¦](https://zh.wikipedia.org/wiki/ç§‘å­¦)ä¸­ï¼Œ**æµ‹é‡è¯¯å·®**ï¼ˆè‹±è¯­ï¼šmeasurement errorï¼‰æˆ–**è§‚æµ‹è¯¯å·®**ï¼ˆobservational errorï¼‰ç®€ç§°**è¯¯å·®**ï¼ˆerrorï¼‰ï¼Œæ˜¯[æµ‹é‡](https://zh.wikipedia.org/wiki/æµ‹é‡)ç»“æœåç¦»[çœŸå€¼](https://zh.wikipedia.org/wiki/çœŸå€¼)çš„ç¨‹åº¦ã€‚å¯¹ä»»ä½•ä¸€ä¸ªç‰©ç†é‡è¿›è¡Œçš„æµ‹é‡éƒ½ä¸å¯èƒ½å¾—å‡ºä¸€ä¸ªç»å¯¹å‡†ç¡®çš„æ•°å€¼ï¼Œå³ä½¿ä½¿ç”¨æµ‹é‡æŠ€æœ¯æ‰€èƒ½è¾¾åˆ°çš„æœ€å®Œå–„çš„æ–¹æ³•ï¼Œæµ‹å‡ºçš„æ•°å€¼ä¹Ÿå’ŒçœŸå®å€¼å­˜åœ¨å·®å¼‚ï¼Œè¿™ç§æµ‹é‡å€¼å’ŒçœŸå®å€¼çš„å·®å¼‚ç§°ä¸ºè¯¯å·®ã€‚è¯¯å·®æ ¹æ®æ•°å€¼è®¡ç®—æ–¹å¼å¯åˆ†ä¸ºç»å¯¹è¯¯å·®å’Œç›¸å¯¹è¯¯å·®ï¼Œä¹Ÿå¯ä»¥æ ¹æ®è¯¯å·®æ¥æºåˆ†ä¸ºç³»ç»Ÿè¯¯å·®ã€éšæœºè¯¯å·®å’Œæ¯›è¯¯å·®ã€‚

æµ‹é‡è¯¯å·®ï¼ˆé™¤äº†æ¯›è¯¯å·®å¤–ï¼‰å¹¶ä¸æ˜¯â€œé”™è¯¯â€ï¼Œæ˜¯äº‹ç‰©å›ºæœ‰çš„ä¸ç¡®å®šæ€§å› ç´ åœ¨é‡æµ‹æ—¶çš„ä½“ç°ã€‚

## 2023å¹´9æœˆ1æ—¥

### ä¸€ã€ç‹¬çƒ­ï¼ˆOne-Hotï¼‰ç¼–ç 

One-Hotç¼–ç ï¼Œåˆç§°ä¸ºä¸€ä½æœ‰æ•ˆç¼–ç ï¼Œä¸»è¦æ˜¯é‡‡ç”¨Nä½çŠ¶æ€å¯„å­˜å™¨æ¥å¯¹Nä¸ªçŠ¶æ€è¿›è¡Œç¼–ç ï¼Œæ¯ä¸ªçŠ¶æ€éƒ½ç”±ä»–ç‹¬ç«‹çš„å¯„å­˜å™¨ä½ï¼Œå¹¶ä¸”åœ¨ä»»æ„æ—¶å€™åªæœ‰ä¸€ä½æœ‰æ•ˆã€‚

One-Hotç¼–ç æ˜¯åˆ†ç±»å˜é‡ä½œä¸ºäºŒè¿›åˆ¶å‘é‡çš„è¡¨ç¤ºã€‚è¿™é¦–å…ˆè¦æ±‚å°†åˆ†ç±»å€¼æ˜ å°„åˆ°æ•´æ•°å€¼ã€‚ç„¶åï¼Œæ¯ä¸ªæ•´æ•°å€¼è¢«è¡¨ç¤ºä¸ºäºŒè¿›åˆ¶å‘é‡ï¼Œé™¤äº†æ•´æ•°çš„ç´¢å¼•ä¹‹å¤–ï¼Œå®ƒéƒ½æ˜¯é›¶å€¼ï¼Œå®ƒè¢«æ ‡è®°ä¸º1ã€‚

å¬æ¦‚å¿µçš„è¯æ˜¾å¾—æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªä¾‹å­ã€‚

å‡è®¾æˆ‘ä»¬æœ‰ä¸€ç¾¤å­¦ç”Ÿï¼Œä»–ä»¬å¯ä»¥é€šè¿‡å››ä¸ªç‰¹å¾æ¥å½¢å®¹ï¼Œåˆ†åˆ«æ˜¯ï¼š

-   æ€§åˆ«ï¼š[â€œç”·â€ï¼Œâ€œå¥³â€]
-   å¹´çº§ï¼š[â€œåˆä¸€â€ï¼Œâ€œåˆäºŒâ€ï¼Œâ€œåˆä¸‰â€]
-   å­¦æ ¡ï¼š[â€œä¸€ä¸­â€ï¼Œâ€œäºŒä¸­â€ï¼Œâ€œä¸‰ä¸­â€ï¼Œâ€œå››ä¸­â€]

ä¸¾ä¸ªä¾‹å­ï¼Œç”¨ä¸Šè¿°å››ä¸ªç‰¹å¾æ¥æè¿°å°æ˜åŒå­¦ï¼Œå³â€œç”·ç”Ÿï¼Œåˆä¸€ï¼Œæ¥è‡ªäºŒä¸­â€ï¼Œå¦‚æœç‰¹å¾ç±»åˆ«æ˜¯æœ‰åºçš„è¯ï¼Œæˆ‘ä»¬èƒ½å¤Ÿç”¨è¡¨ç¤ºé¡ºåºçš„æ•°ç»„è¡¨ç¤º

å³â€œç”·ç”Ÿï¼Œåˆä¸€ï¼Œæ¥è‡ªä¸€ä¸­â€   ==>   [0,0,1]

ä½†æ˜¯è¿™æ ·çš„ç‰¹å¾å¤„ç†å¹¶ä¸èƒ½ç›´æ¥æ”¾å…¥æœºå™¨å­¦ä¹ ç®—æ³•ä¸­ï¼Œå› ä¸ºç±»åˆ«ä¹‹é—´æ˜¯æ— åºçš„ã€‚

è¿™æ—¶å€™å°±å¯ä»¥ç”¨ç‹¬çƒ­ç¼–ç çš„å½¢å¼æ¥è¡¨ç¤ºäº†ï¼Œæˆ‘ä»¬ç”¨é‡‡ç”¨Nä½çŠ¶æ€å¯„å­˜å™¨æ¥å¯¹Nä¸ªçŠ¶æ€è¿›è¡Œç¼–ç ï¼Œæ‹¿ä¸Šé¢çš„ä¾‹å­æ¥è¯´ï¼Œå°±æ˜¯ï¼š

| æ€§åˆ« | [â€œç”·â€ï¼Œâ€œå¥³â€]                     | N=2  | ç”·ï¼š1 0 å¥³ï¼š0 1                                      |
| :--- | :------------------------------- | :--- | :--------------------------------------------------- |
| å¹´çº§ | [â€œåˆä¸€â€ï¼Œâ€œåˆäºŒâ€ï¼Œâ€œåˆä¸‰â€]         | N=3  | åˆä¸€ï¼š1 0 0  åˆäºŒï¼š0 1 0åˆä¸‰ï¼š0 0 1                  |
| å­¦æ ¡ | [â€œä¸€ä¸­â€ï¼Œâ€œäºŒä¸­â€ï¼Œâ€œä¸‰ä¸­â€ï¼Œâ€œå››ä¸­â€] | N=4  | ä¸€ä¸­ï¼š1 0 0 0äºŒä¸­ï¼š0 1 0 0ä¸‰ä¸­ï¼š0 0 1 0å››ä¸­ï¼š0 0 0 1 |

å› æ­¤ï¼Œå½“æˆ‘ä»¬å†æ¥æè¿°å°æ˜çš„æ—¶å€™ï¼Œå°±å¯ä»¥é‡‡ç”¨ [1 0 1 0 0 0 1 0 0] 



åœ¨å¾ˆå¤šæœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œç‰¹å¾å¹¶ä¸æ€»æ˜¯è¿ç»­å€¼ï¼Œè€Œæœ‰å¯èƒ½æ˜¯åˆ†ç±»å€¼ã€‚

ç¦»æ•£ç‰¹å¾çš„ç¼–ç åˆ†ä¸ºä¸¤ç§æƒ…å†µï¼š

-   ç¦»æ•£ç‰¹å¾çš„å–å€¼ä¹‹é—´æ²¡æœ‰å¤§å°çš„æ„ä¹‰ï¼Œæ¯”å¦‚$colorï¼š[red,blue]$,é‚£ä¹ˆå°±ä½¿ç”¨one-hotç¼–ç 

-   ç¦»æ•£ç‰¹å¾çš„å–å€¼æœ‰å¤§å°çš„æ„ä¹‰ï¼Œæ¯”å¦‚$size:[X,XL,XXL]$, é‚£ä¹ˆå°±ä½¿ç”¨æ•°å€¼çš„æ˜ å°„${X:1,XL:2,XXL:3}$

### äºŒã€å…³äºpythonä¸­æ•°æ®ç±»å‹çš„shapeå±æ€§

```python
import cv2 as cv

bgr_img = cv.imread("/img_path", cv.IMREAD_COLOR)
print (bgr_img.shape)
```



**è¯¥æ®µä»£ç çš„è¾“å‡ºå°†ä¼šæ˜¯å›¾ç‰‡çš„è¡Œæ•°+åˆ—æ•°+é€šé“æ•°**

### ä¸‰ã€zero-mean normalization, z-scoreæ ‡å‡†åŒ–

è®¾éšæœºå˜é‡$X$å…·æœ‰æ•°å­¦æœŸæœ›$E(X)=\mu$, æ–¹å·®$D(x)=\alpha^2 \neq 0$. è®°$X^*=\frac{X-\mu}{\sigma}$, å«åšéšæœºå˜é‡$X$çš„æ ‡å‡†åˆå§‹åŒ–. å°†éšæœºå˜é‡çš„æœŸæœ›åŒ–ä¸º0, æ–¹å·®åŒ–ä¸º1. è¯æ˜:

$$
E(X^*)=\frac{1}{\sigma}E(X-\mu)=\frac{1}{\sigma}(E(X)-\mu)=0 \label{1}
$$

$$
D(X^*)=E(X^{*2}) - E(X^*)^2 = E(\frac{X-\mu}{\sigma})^2 = \frac{1}{\sigma^2} E(X-\mu)^2 = \frac{\sigma^2}{\sigma^2} = 1 \label{2}
$$

### å››ã€ æ·±åº¦å­¦ä¹ ä¸­Epochã€Batchä»¥åŠBatch sizeçš„è®¾å®šğŸš€

- **Epochï¼ˆæ—¶æœŸï¼‰ï¼š**

å½“ä¸€ä¸ªå®Œæ•´çš„æ•°æ®é›†é€šè¿‡äº†ç¥ç»ç½‘ç»œä¸€æ¬¡å¹¶ä¸”è¿”å›äº†ä¸€æ¬¡ï¼Œè¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºä¸€æ¬¡>epochã€‚ï¼ˆä¹Ÿå°±æ˜¯è¯´ï¼Œæ‰€æœ‰è®­ç»ƒæ ·æœ¬åœ¨ç¥ç»ç½‘ç»œä¸­éƒ½ è¿›è¡Œäº†ä¸€æ¬¡æ­£å‘ä¼ æ’­ å’Œä¸€æ¬¡åå‘ä¼ æ’­ ï¼‰

å†é€šä¿—ä¸€ç‚¹ï¼Œä¸€ä¸ªEpochå°±æ˜¯å°†æ‰€æœ‰è®­ç»ƒæ ·æœ¬è®­ç»ƒä¸€æ¬¡çš„è¿‡ç¨‹ã€‚

ç„¶è€Œï¼Œå½“ä¸€ä¸ªEpochçš„æ ·æœ¬ï¼ˆä¹Ÿå°±æ˜¯æ‰€æœ‰çš„è®­ç»ƒæ ·æœ¬ï¼‰æ•°é‡å¯èƒ½å¤ªè¿‡åºå¤§ï¼ˆå¯¹äºè®¡ç®—æœºè€Œè¨€ï¼‰ï¼Œå°±éœ€è¦æŠŠå®ƒåˆ†æˆå¤šä¸ªå°å—ï¼Œä¹Ÿå°±æ˜¯å°±æ˜¯åˆ†æˆå¤šä¸ªBatch æ¥è¿›è¡Œè®­ç»ƒã€‚

-   **Batchï¼ˆæ‰¹ / ä¸€æ‰¹æ ·æœ¬ï¼‰ï¼š**

å°†æ•´ä¸ªè®­ç»ƒæ ·æœ¬åˆ†æˆè‹¥å¹²ä¸ªBatchã€‚

-   **Batch_Sizeï¼ˆæ‰¹å¤§å°ï¼‰ï¼š**

æ¯æ‰¹æ ·æœ¬çš„å¤§å°ã€‚

-   **Iterationï¼ˆä¸€æ¬¡è¿­ä»£ï¼‰ï¼š**

è®­ç»ƒä¸€ä¸ªBatchå°±æ˜¯ä¸€æ¬¡Iterationï¼ˆè¿™ä¸ªæ¦‚å¿µè·Ÿç¨‹åºè¯­è¨€ä¸­çš„è¿­ä»£å™¨ç›¸ä¼¼ï¼‰

-   **ä¸ºä»€ä¹ˆè¦ä½¿ç”¨å¤šäºä¸€ä¸ªepoch?**

åœ¨ç¥ç»ç½‘ç»œä¸­ä¼ é€’å®Œæ•´çš„æ•°æ®é›†ä¸€æ¬¡æ˜¯ä¸å¤Ÿçš„ï¼Œè€Œä¸”æˆ‘ä»¬éœ€è¦å°†å®Œæ•´çš„æ•°æ®é›†åœ¨åŒæ ·çš„ç¥ç»ç½‘ç»œä¸­ä¼ é€’å¤šæ¬¡ã€‚ä½†è¯·è®°ä½ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯æœ‰é™çš„æ•°æ®é›†ï¼Œå¹¶ä¸”æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹å³æ¢¯åº¦ä¸‹é™æ¥ä¼˜åŒ–å­¦ä¹ è¿‡ç¨‹ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚å› æ­¤ä»…ä»…æ›´æ–°ä¸€æ¬¡æˆ–è€…è¯´ä½¿ç”¨ä¸€ä¸ªepochæ˜¯ä¸å¤Ÿçš„ã€‚



## 2023å¹´9æœˆ2æ—¥

### ä¸€ã€å…³äºpythonä¸­çš„shapeå±æ€§ï¼ˆè¡¥å……ï¼‰

```python
import numpy as np

a = np.array([1, 2, 3])
a.shape # (3,)

a = np.array([[1, 2, 3]])
a.shape # (1, 3)
```

## 2023å¹´9æœˆ4æ—¥

### ä¸€ã€csvæ–‡ä»¶çš„æ•°æ®è¯»å–å¹¶æŸ¥çœ‹æ•°æ®ç»“æ„ä¹‹é—´å…³ç³»

```python
import pandas as pd
import matplotlib.pyplot as plt

data = pd.concat([train_df['Sold Price'], train_df['Listed Price']], axis=1)
fig = plt.scatter(data, x='Listed Price', y='Sold Price')
fig.show()
```

### äºŒã€csvæ–‡ä»¶ä¸­æŸ¥çœ‹æŸä¸€ç±»æ•°æ®çš„å€¼åˆ†å¸ƒ

```python
import seaborn as sns
import matplotlib.pyplot as plt

# å‡è®¾ train_data æ˜¯ä¸€ä¸ªåŒ…å« "SalePrice" åˆ—çš„ DataFrame

# ç»˜åˆ¶ SalePrice åˆ—çš„ç›´æ–¹å›¾
sns.displot(train_data["SalePrice"], kde=True)  # ä½¿ç”¨ kde=True æ·»åŠ æ ¸å¯†åº¦ä¼°è®¡æ›²çº¿
plt.title('Distribution of SalePrice')
plt.xlabel('SalePrice')
plt.ylabel('Frequency')
plt.show()
```

## 2023å¹´9æœˆ6æ—¥

### ä¸€ã€å›¾åƒå·ç§¯åçš„è¾“å‡ºå½¢çŠ¶

#### 1.ç›´æ¥å·ç§¯

<center class="half">
    <img src="./assets/4.png" style="zoom:50%;"/>
    <img src="./assets/no_padding_no_strides.gif" style="zoom:50%;"/>
</center>

-   è¾“å…¥$\pmb{X}: n_h \times n_w$
-   å·ç§¯æ ¸ $\pmb{W}: k_h \times k_w$
-   åå·®$b \in \mathbb{R}$
-   è¾“å‡º$\pmb{Y}:(n_h-k_h+1) \times(n_w-k_w+1)$

#### 2.å¡«å……å·ç§¯

<center class="half">
    <img src="./assets/5.png" style="zoom:50%;"/>
    <img src="./assets/same_padding_no_strides_transposed.gif" style="zoom:50%;"/>
</center>

-   é«˜åº¦(è¡Œ)å¡«å……$p_h$, å®½åº¦(åˆ—)å¡«å……$p_w$
-   è¾“å‡º$\pmb{Y}:(n_h-k_h+p_h+1) \times(n_w-k_w+p_w+1)$

#### 3.æ­¥å¹…

<center class="half">
    <img src="./assets/6.png" style="zoom:50%;"/>
    <img src="./assets/no_padding_strides.gif" style="zoom:50%;"/>
</center>

-   é«˜åº¦(è¡Œ)æ­¥å¹…$s_h$, å®½åº¦(åˆ—)æ­¥å¹…$s_w$
-   è¾“å‡º$\pmb{Y}:\frac{n_h-k_h+p_h+s_h}{s_h} \times\frac{n_w-k_w+p_w+s_w}{s_w}$ï¼ˆå‘ä¸‹å–æ•´ï¼‰

#### 4.æ„Ÿå—é‡(Receptive Field, RF)å¤§å°

$S_i = \Pi^i_{i-1}Stride_i$ å…¶ä¸­$S_i$è¡¨ç¤ºä¹‹å‰æ‰€æœ‰å±‚çš„æ­¥é•¿çš„ä¹˜ç§¯(ä¸åŒ…æ‹¬æœ¬å±‚)

$RF_{i+1} = RF_i + (k - 1) * S_i$ å…¶ä¸­$k$ä¸ºå·ç§¯æ ¸å¤§å°, $RF_i$ä¸ºä¸Šä¸€å±‚çš„æ„Ÿå—é‡å¤§å°, $RF_{i+1}$è¡¨ç¤ºå½“å‰å±‚æ„Ÿå—é‡å¤§å°.

## 2023å¹´9æœˆ7æ—¥

### ä¸€ã€ç»å…¸çš„ç‚¹æ‰©æ•£å‡½æ•°ä¼°è®¡ (æˆ‘ç”¨ä¸èµ·æ¥)

åœ¨æ›å…‰æ—¶é—´$T$å†…åŒ€é€Ÿç›´çº¿è¿åŠ¨ä½ç§»é‡ä¸º$R$, æ²¿æ°´å¹³è½´æˆ$\theta$è§’å˜åŒ–, åˆ™ç‚¹æ‰©æ•£å‡½æ•°çš„é¢‘è°±å½¢å¼ä¸º:
$$
H(u, v) = \frac{T\sin[\pi(uR\cos{\theta} + vR\sin{\theta})]}{\pi(uR\cos{\theta}+vR\sin{\theta})}\exp{(-j\pi(uR\cos{\theta}+vR\sin{\theta}))}
$$

### äºŒã€torchçš„Tensoræ•°æ®ç±»å‹çš„å½¢çŠ¶

```python
>>>import torch
>>>x = torch.rand((8, 8))
>>>x
tensor([[1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.]])
>>>x.shape
torch.Size([8, 8])
>>>(1, 1) + x.shape
(1, 1, 8, 8)
>>>x = x.reshape((1, 1) + x.shape) #æ­¤å¤„çš„æ„æ€ä¸ºå°†x reshape æˆè¾“å‡ºé€šé“æ•°ä¸º1, è¾“å…¥é€šé“ä¸º1å†åŠ x.shapeçš„shape. 
# æ­¤å¤–, è¯¥å¥ç­‰ä»·äºx = x.reshape((1, 1, x.shape[0], x.shape[1]))
>>>x.shape
torch.Size([1, 1, 8, 8])
```

### ä¸‰ã€å¤šä¸ªè¾“å…¥è¾“å‡ºé€šé“

#### 1.å¤šè¾“å…¥é€šé“

<img src="./assets/image-20230907221407932.png" alt="image-20230907221407932" style="zoom:50%;" />

-   è¾“å…¥ $\pmb{X}: c_i \times n_h \times n_w$
-   æ ¸ $\pmb{W}: c_i \times k_h \times k_w$
-   è¾“å‡º $\pmb{Y}: m_h \times m_w$



#### 2.å¤šè¾“å‡ºé€šé“

-   è¾“å…¥$\pmb{X}: c_i \times n_h \times n_w$
-   æ ¸$\pmb{W}: c_0 \times c_i \times k_h \times k_w$
-   è¾“å‡º$\pmb{Y}: c_0 \times m_h \times m_w$

## 2023å¹´9æœˆ11æ—¥

### ä¸€ã€æ± åŒ–å±‚

-   æ± åŒ–å±‚è§£å†³å·ç§¯å¯¹ä½ç½®æ•æ„Ÿçš„é—®é¢˜ï¼Œæ‰€ä»¥ç»è¿‡å•ï¼ˆå¤šï¼‰ä¸ªå·ç§¯å±‚åéƒ½è¦è¿›è¡Œæ± åŒ–å±‚æ“ä½œï¼›
-   ç»è¿‡æ± åŒ–å±‚åè¾“å…¥é€šé“ç­‰äºè¾“å‡ºé€šé“ï¼›
-   ç»è¿‡æ± åŒ–å±‚åçš„å›¾åƒå¤§å°å’Œè¿‡å·ç§¯å±‚åçš„ç»“æœä¸€è‡´ï¼š$\pmb{shape}:\frac{n_h-k_h+p_h+s_h}{s_h} \times\frac{n_w-k_w+p_w+s_w}{s_w}$
-   å®é™…ä¸Šæ± åŒ–å±‚ä¸­é»˜è®¤strideä¸ºæ± åŒ–å±‚çš„æ ¸å¤§å°ï¼Œåœ¨ä»£ç ä¸­å¯ä»¥æŒ‡å®šstride.

```python
import torch 
from torch import nn

input = torch.tensor([[[[1, 3, 2, 1],
                       	[2, 9, 1, 1],
                       	[1, 3, 2, 3],
                       	[5, 6, 1, 2]]]], dtype=torch.float32)

net = nn.MaxPool2d(kernel_size=3, padding=1)

net(input).shape

#è¾“å‡ºtorch.Size([1, 1, 2, 2])
```



### äºŒã€å·ç§¯ç¥ç»ç½‘ç»œï¼ˆLeNetï¼‰

<img src="./assets/image-20230911214818663.png" alt="image-20230911214818663" style="zoom:50%;" />

```python
net = nn.Sequential(nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),
                    nn.AvgPool2d(kernel_size=2, stride=2),
                    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
                    nn.AvgPool2d(kernel_size=2, stride=2),
                    nn.Flatten(),
                    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
                    nn.Linear(120, 84), nn.Sigmoid(),
                    nn.Linear(84, 10))
                    
X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__,'output shape: \t',X.shape)

# è¾“å‡ºä¸ºï¼š
# Conv2d output shape: 	 	 torch.Size([1, 6, 28, 28])
# Sigmoid output shape: 	 torch.Size([1, 6, 28, 28])
# AvgPool2d output shape: 	 torch.Size([1, 6, 14, 14])
# Conv2d output shape: 	 	 torch.Size([1, 16, 10, 10])
# Sigmoid output shape: 	 torch.Size([1, 16, 10, 10])
# AvgPool2d output shape: 	 torch.Size([1, 16, 5, 5])
# Flatten output shape: 	 torch.Size([1, 400])
# Linear output shape: 	 	 torch.Size([1, 120])
# Sigmoid output shape: 	 torch.Size([1, 120])
# Linear output shape: 	 	 torch.Size([1, 84])
# Sigmoid output shape: 	 torch.Size([1, 84])
# Linear output shape: 	 	 torch.Size([1, 10])

```

### ä¸‰ã€AlexNetï¼ˆè®°å¾—çœ‹è®ºæ–‡ï¼‰

<img src="./assets/image-20230911215217788.png" alt="image-20230911215217788" style="zoom:50%;" />

```python
net = nn.Sequential(
    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Flatten(),
    nn.Linear(6400, 4096), nn.ReLU(),
    nn.Dropout(p=0.5), # å…¨è¿æ¥å±‚é˜²æ­¢è¿‡æ‹Ÿåˆ
    nn.Linear(4096, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(4096, 10))

X = torch.randn(1, 1, 224, 224)
for layer in net:
    X=layer(X)
    print(layer.__class__.__name__,'output shape:\t',X.shape)
    
# è¾“å‡ºä¸ºï¼š    
# Conv2d output shape:	 torch.Size([1, 96, 54, 54])
# ReLU output shape:	 torch.Size([1, 96, 54, 54])
# MaxPool2d output shape:	 torch.Size([1, 96, 26, 26])
# Conv2d output shape:	 torch.Size([1, 256, 26, 26])
# ReLU output shape:	 torch.Size([1, 256, 26, 26])
# MaxPool2d output shape:	 torch.Size([1, 256, 12, 12])
# Conv2d output shape:	 torch.Size([1, 384, 12, 12])
# ReLU output shape:	 torch.Size([1, 384, 12, 12])
# Conv2d output shape:	 torch.Size([1, 384, 12, 12])
# ReLU output shape:	 torch.Size([1, 384, 12, 12])
# Conv2d output shape:	 torch.Size([1, 256, 12, 12])
# ReLU output shape:	 torch.Size([1, 256, 12, 12])
# MaxPool2d output shape:	 torch.Size([1, 256, 5, 5])
# Flatten output shape:	 torch.Size([1, 6400])
# Linear output shape:	 torch.Size([1, 4096])
# ReLU output shape:	 torch.Size([1, 4096])
# Dropout output shape:	 torch.Size([1, 4096])
# Linear output shape:	 torch.Size([1, 4096])
# ReLU output shape:	 torch.Size([1, 4096])
# Dropout output shape:	 torch.Size([1, 4096])
# Linear output shape:	 torch.Size([1, 10])  
```

### å››ã€VGGï¼ˆ**V**isual **G**eometry **G**roupï¼‰

VGG16ç›¸æ¯”AlexNetçš„ä¸€ä¸ªæ”¹è¿›æ˜¯**é‡‡ç”¨è¿ç»­çš„å‡ ä¸ª3x3çš„å·ç§¯æ ¸ä»£æ›¿AlexNetä¸­çš„è¾ƒå¤§å·ç§¯æ ¸ï¼ˆ11x11ï¼Œ7x7ï¼Œ5x5ï¼‰**ï¼Œ å¯¹äºç»™å®šçš„æ„Ÿå—é‡ï¼ˆä¸è¾“å‡ºæœ‰å…³çš„è¾“å…¥å›¾ç‰‡çš„å±€éƒ¨å¤§å°ï¼‰ï¼Œ**é‡‡ç”¨å †ç§¯çš„å°å·ç§¯æ ¸æ˜¯ä¼˜äºé‡‡ç”¨å¤§çš„å·ç§¯æ ¸ï¼Œå› ä¸ºå¤šå±‚éçº¿æ€§å±‚å¯ä»¥å¢åŠ ç½‘ç»œæ·±åº¦æ¥ä¿è¯å­¦ä¹ æ›´å¤æ‚çš„æ¨¡å¼ï¼Œè€Œä¸”ä»£ä»·è¿˜æ¯”è¾ƒå°ï¼ˆå‚æ•°æ›´å°‘ï¼‰**ã€‚åœ¨VGGä¸­ï¼Œä½¿ç”¨äº†3ä¸ª3x3å·ç§¯æ ¸æ¥ä»£æ›¿7x7å·ç§¯æ ¸ï¼Œä½¿ç”¨äº†2ä¸ª3x3å·ç§¯æ ¸æ¥ä»£æ›¿5*5å·ç§¯æ ¸ï¼Œè¿™æ ·åšçš„ä¸»è¦ç›®çš„æ˜¯åœ¨ä¿è¯å…·æœ‰ç›¸åŒæ„ŸçŸ¥é‡çš„æ¡ä»¶ä¸‹ï¼Œæå‡äº†ç½‘ç»œçš„æ·±åº¦ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šæå‡äº†ç¥ç»ç½‘ç»œçš„æ•ˆæœã€‚VGGä¸­å›ºå®šæœ‰ä¸‰ä¸ªå…¨è¿æ¥å±‚ï¼Œå› æ­¤VGGâ€”(3+x)ï¼Œå…¶ä¸­xä¸ºVGGå—é‡å¤çš„ä¸ªæ•°ã€‚

VGGå—ç”±å¤šä¸ªå·ç§¯å±‚å’Œä¸€ä¸ªæœ€å¤§æ± åŒ–å±‚ç»„æˆï¼Œè§ä¸‹å›¾

<center class="half">
    <img src="./assets/image-20230911220752152.png" style="zoom:50%;"/>
</center>

```python
def vgg_block(num_convs, in_channels, out_channels):
    layers = []
    for _ in range(num_convs):
        layers.append(nn.Conv2d(in_channels, out_channels,
                                kernel_size=3, padding=1))
        layers.append(nn.ReLU())
        in_channels = out_channels
    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))
    return nn.Sequential(*layers)

conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))

def vgg(conv_arch):
    conv_blks = []
    in_channels = 1
    for (num_convs, out_channels) in conv_arch: #VGG-4
        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))
        in_channels = out_channels

    return nn.Sequential(
        *conv_blks, nn.Flatten(),
        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 10))

net = vgg(conv_arch)

X = torch.randn(size=(1, 1, 224, 224))
for blk in net:
    X = blk(X)
    print(blk.__class__.__name__,'output shape:\t',X.shape)
    
    
# è¾“å‡ºä¸º:
# Sequential output shape:	 torch.Size([1, 64, 112, 112])
# Sequential output shape:	 torch.Size([1, 128, 56, 56])
# Sequential output shape:	 torch.Size([1, 256, 28, 28])
# Sequential output shape:	 torch.Size([1, 512, 14, 14])
# Sequential output shape:	 torch.Size([1, 512, 7, 7])
# Flatten output shape:	 torch.Size([1, 25088])
# Linear output shape:	 torch.Size([1, 4096])
# ReLU output shape:	 torch.Size([1, 4096])
# Dropout output shape:	 torch.Size([1, 4096])
# Linear output shape:	 torch.Size([1, 4096])
# ReLU output shape:	 torch.Size([1, 4096])
# Dropout output shape:	 torch.Size([1, 4096])
# Linear output shape:	 torch.Size([1, 10])
```

### äº”ã€éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆstochastic gradient descent, SGDï¼‰

![image-20230912115449755](./assets/image-20230912115449755.png)

â€‹											ğŸ˜**æƒé‡æ›´æ–°å…¬å¼ä¸º: $w_t = w_{t-1} - \eta \frac{\partial{\mathcal{L}}}{\partial{w_{t-1}}}$**

å…¶ä¸­, $\mathcal{L}$ä¸ºæŸå¤±å‡½æ•°, $w_t$ä¸ºå½“å‰æ›´æ–°åçš„æƒé‡, $w_{t-1}$ä¸ºä¸Šæ›´æ–°å‰çš„æƒé‡ï¼Œ$\eta$ä¸ºå­¦ä¹ ç‡ã€‚è¿™ç§SGDä¼˜åŒ–æ–¹æ³•å®é™…ä¸Šè¢«ç§°ä¸ºvanilla SGDã€‚

pytorchä¸­çš„è°ƒç”¨å‡½æ•°ä¸ºï¼ˆä¼ªä»£ç ï¼‰ï¼š

```python
import torch
from torch import optim

...
...
...
model = net()

optimizer = optim.SGD(model.parameter, lr=...)

for epoch in range(epochs):
    optimizer.zero_grad() # æ¸…ç©ºæ¢¯åº¦
    ...
    ...
    ...
    optimizer.step() #æ›´æ–°å‚æ•°
```

æ­¤å¤–æœ‰ä¼˜åŒ–åçš„SGDæ–¹æ³•ä¸ºMomentum SGDï¼Œä»–çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼Œå…¶ä¸­$\beta_1$å¸¸è¢«è®¾ä¸º0.9, $\beta_2$å¸¸è¢«è®¾ä¸º0.1ã€‚
$$
\text{g}_t = \frac{\partial{\mathcal{L}}}{\partial{w_{t-1}}} \\ m_t = \beta_1 m_{t-1} + \beta_2 \text{g}_t \\ w_t = w_{t-1} - \eta m_t
$$

### å…­ã€æ‰¹é‡å½’ä¸€åŒ–





## 2023å¹´9æœˆ14æ—¥

### ä¸€ã€è½¬ç½®å·ç§¯

åå·ç§¯è¾“å‡ºç‰¹å¾å°ºåº¦å…¬å¼ï¼š$W^{\prime} = (W-1)*S + K - 2P$

## 2023å¹´9æœˆ15æ—¥

### ä¸€ã€ä»¿å°„å˜æ¢

ä»¿å°„å˜æ¢ï¼ˆAffine Transformationï¼‰æ˜¯æŒ‡åœ¨å‘é‡ç©ºé—´ä¸­è¿›è¡Œä¸€æ¬¡çº¿æ€§å˜æ¢(ä¹˜ä»¥ä¸€ä¸ªçŸ©é˜µ)å’Œä¸€æ¬¡å¹³ç§»(åŠ ä¸Šä¸€ä¸ªå‘é‡)ï¼Œå˜æ¢åˆ°å¦ä¸€ä¸ªå‘é‡ç©ºé—´çš„è¿‡ç¨‹ã€‚

## 2023å¹´9æœˆ19æ—¥

### ä¸€ã€PyTorchæ¨¡å‹ä¿å­˜

æ¨¡å‹çš„æœ¬è´¨æ˜¯ä¸€å †ç”¨æŸç§ç»“æ„å­˜å‚¨èµ·æ¥çš„å‚æ•°ï¼Œæ‰€ä»¥åœ¨ä¿å­˜çš„æ—¶å€™æœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ–¹å¼æ˜¯ç›´æ¥å°†æ•´ä¸ªæ¨¡å‹ä¿å­˜ä¸‹æ¥ï¼Œä¹‹åç›´æ¥åŠ è½½æ•´ä¸ªæ¨¡å‹ï¼Œä½†è¿™æ ·ä¼šæ¯”è¾ƒè€—å†…å­˜ï¼›å¦ä¸€ç§æ˜¯åªä¿å­˜æ¨¡å‹çš„å‚æ•°ï¼Œä¹‹åç”¨åˆ°çš„æ—¶å€™å†åˆ›å»ºä¸€ä¸ªåŒæ ·ç»“æ„çš„æ–°æ¨¡å‹ï¼Œç„¶åæŠŠæ‰€ä¿å­˜çš„å‚æ•°å¯¼å…¥æ–°æ¨¡å‹ã€‚

## 2023å¹´10æœˆ16æ—¥

### ä¸€ã€å…‰æµ

<img src="./assets/image-20231016114825338.png" alt="image-20231016114825338" style="zoom:50%;" />

å…‰æµï¼ˆoptical flowï¼‰æ˜¯ç©ºé—´è¿åŠ¨ç‰©ä½“åœ¨è§‚å¯Ÿæˆåƒå¹³é¢ä¸Šçš„**åƒç´ è¿åŠ¨çš„ç¬æ—¶é€Ÿåº¦**, åœ¨æ—¶é—´é—´éš”å¾ˆå°ï¼ˆæ¯”å¦‚è§†é¢‘çš„è¿ç»­å‰åä¸¤å¸§ä¹‹é—´ï¼‰æ—¶ï¼Œä¹Ÿç­‰åŒäºç›®æ ‡ç‚¹çš„ä½ç§»ã€‚

å‰æå‡è®¾ï¼š**1.äº®åº¦æ’å®š(ç°åº¦ä¸€è‡´æ€§å‡è®¾)    2.è¿åŠ¨å¹…åº¦å°**, ä»è€Œæœ‰:
$$
I(x,y,t) = I(x+dx, y+dy, t+dt) \\ 
\rightarrow  I(x,y,t) = I(x, y, z) + \frac{\partial{I}}{\partial{x}}*dx + \frac{\partial{I}}{\partial{y}}*dy + \frac{\partial{I}}{\partial{t}}*dt \\
\rightarrow \frac{\partial{I}}{\partial{x}}*dx + \frac{\partial{I}}{\partial{y}}*dy + \frac{\partial{I}}{\partial{t}}*dt = 0
$$

### äºŒã€pythonå˜é‡å‰åŠ æ˜Ÿå·çš„æ„ä¹‰

```python
def add(x, y):
	return x + y
```

-   åˆ—è¡¨æˆ–å…ƒç»„å‰é¢åŠ æ˜Ÿå·ä½œç”¨æ˜¯å°†åˆ—è¡¨è§£å¼€æˆä¸¤ä¸ªç‹¬ç«‹çš„å‚æ•°ï¼Œä¼ å…¥å‡½æ•°

    ```
    a = [1, 2]
    
    b = (1, 2)
    
    add(*a)
    >>>3
    
    add(*b)
    >>>3
    ```

-   å­—å…¸å‰é¢åŠ ä¸¤ä¸ªæ˜Ÿå·ï¼Œæ˜¯å°†å­—å…¸çš„å€¼è§£å¼€æˆç‹¬ç«‹çš„å…ƒç´ ä½œä¸ºå½¢å‚ã€‚æ³¨æ„å­—å…¸çš„é”®è¦å’Œå½¢å‚åä¸€è‡´

    ```python
    c = {'x': 1, 'y': 2}
    
    add(**c)
    ```

## 2023å¹´10æœˆ17æ—¥

### ä¸€ã€è®ºæ–‡ä¸­10xä»£è¡¨ä»€ä¹ˆæ„æ€

ç­”ï¼š 10x åå€äºæŸæŸæŸï¼Œ 10x less æ˜¯æŸæŸæŸçš„ååˆ†ä¹‹ä¸€

### äºŒã€Layer Normalizationä¸Batch Normlization

![7](./assets/7.png)

BNå¦‚å³ä¾§æ‰€ç¤ºï¼Œå®ƒæ˜¯å–ä¸åŒæ ·æœ¬çš„åŒä¸€ä¸ªé€šé“çš„ç‰¹å¾åšå½’ä¸€åŒ–ï¼›LNåˆ™æ˜¯å¦‚å·¦ä¾§æ‰€ç¤ºï¼Œå®ƒå–çš„æ˜¯åŒä¸€ä¸ªæ ·æœ¬çš„ä¸åŒé€šé“åšå½’ä¸€åŒ–ã€‚

BNæ˜¯æŒ‰ç…§æ ·æœ¬æ•°è®¡ç®—å½’ä¸€åŒ–ç»Ÿè®¡é‡çš„ï¼Œå½“æ ·æœ¬æ•°å¾ˆå°‘æ—¶ï¼Œæ¯”å¦‚è¯´åªæœ‰4ä¸ªã€‚è¿™å››ä¸ªæ ·æœ¬çš„å‡å€¼å’Œæ–¹å·®ä¾¿ä¸èƒ½åæ˜ å…¨å±€çš„ç»Ÿè®¡åˆ†å¸ƒæ¯ï¼Œæ‰€ä»¥åŸºäºå°‘é‡æ ·æœ¬çš„BNçš„æ•ˆæœä¼šå˜å¾—å¾ˆå·®ã€‚åœ¨ä¸€äº›åœºæ™¯ä¸­ï¼Œæ¯”å¦‚è¯´ç¡¬ä»¶èµ„æºå—é™ï¼Œåœ¨çº¿å­¦ä¹ ç­‰åœºæ™¯ï¼ŒBNæ˜¯éå¸¸ä¸é€‚ç”¨çš„ã€‚

### ä¸‰ã€torchå®ç°Hadamardç§¯ä¸æ™®é€šçŸ©é˜µä¹˜ç§¯

-   Hadamardç§¯

``````python
a = torch.Tensor([[1,2], [3,4]])
b = torch.Tensor([[5,6], [7,8]])
hadamard_product = a * b
print('hadamard_product:', hadamard_product)

>>>tensor([[ 5., 12.],
        [21., 32.]])
``````

-   çŸ©é˜µä¹˜ç§¯

``````python
a = torch.Tensor([[1,2], [3,4]])
b = torch.Tensor([[5,6], [7,8]])
matrix_product = torch.matmul(a, b)

>>>tensor([[19., 22.],
        [43., 50.]])
``````

## 2023å¹´10æœˆ18æ—¥

### ä¸€ã€patch_sizeå’Œbatch_size

-   **Batch**æ˜¯**æ‰¹é‡çš„å¤§å°**ï¼Œå°±æ˜¯ä½ è®­ç»ƒçš„æ—¶å€™æ¯æ¬¡è¾“å…¥å¤šå°‘å¼ å›¾ç‰‡ï¼Œæ¯ä¸ª**epoch**æœ‰å¤šä¸ª**Batch**
-   **Patch**æ˜¯**å›¾åƒå—çš„å¤§å°**ï¼Œæ¯”å¦‚è¯´åŸå›¾$1024 * 1024$ï¼Œéšæœºä»å›¾ä¸­è£å‰ªå‡º$256 * 256$å¤§å°çš„å—ï¼Œå°±æ˜¯patchã€‚æ›´å‡†ç¡®æ¥è¯´ï¼šâ€œpatchâ€, æŒ‡ä¸€ä¸ªäºŒç»´å›¾ç‰‡ä¸­çš„å…¶ä¸­ä¸€ä¸ªå°å—, å³ä¸€å¼ äºŒç»´å›¾åƒä¸­æœ‰å¾ˆå¤šä¸ªpatchã€‚ æ­£å¦‚åœ¨ç¥ç»ç½‘ç»œçš„å·ç§¯è®¡ç®—ä¸­, å›¾åƒå¹¶ä¸æ˜¯ä¸€æ•´å—å›¾åƒç›´æ¥åŒå·ç§¯æ ¸è¿›è¡Œè¿ç®—, è€Œæ˜¯è¢«åˆ†æˆäº†å¾ˆå¤šå¾ˆå¤šä¸ªpatchåˆ†åˆ«åŒå·ç§¯æ ¸è¿›è¡Œå·ç§¯è¿ç®—, è¿™äº›patchçš„å¤§å°å–å†³äºå·ç§¯æ ¸çš„size. å·ç§¯æ ¸æ¯æ¬¡åªæŸ¥çœ‹ä¸€ä¸ªpatch, ç„¶åç§»åŠ¨åˆ°å¦ä¸€ä¸ªpatch, ç›´åˆ°å›¾åƒåˆ†æˆçš„æ‰€æœ‰patchéƒ½å‚ä¸å®Œè¿ç®—.
