# **introduction**

在光照昏暗的室内环境下，无人机或无人车等移动设备的运动可能会导致由相机拍摄到的图像出现运动模糊的问题，而这会导致一些像是视觉里程计，目标识别，物体分割等视觉算法的性能明显下降。虽然现在有很多基于CNN或者Transformer的图像恢复算法（此处引用部分去模糊算法）取得了很不错的效果但是他们都有着两个突出的缺陷：复杂的网络结构和极多的模型参数。而这种缺陷会导致网络的前向推理速度变慢并且需要大量的计算量，对于移动端设备来说这种缺陷是致命的这意味着这些算法不能在现实场景中很好的运行。为了在获得低延时，低模型参数的同时得到一个较好的去模糊效果，本文设计了一个基于轻量化的卷积神经网络和可分离的自注意力Transformer的简单网络结构。本网络在获得极低的延时（10ms处理一张752x480的图像）和较小的模型大小（12.9mb）同时可以获得较高的去模糊效果（31.23 PSNR， 0.9421SSIM）。本文的主要的主要贡献如下：

-   受经典的核估计去模糊方法启发，本文采用可调整的可变形卷积来自适应的调整采样点的位置和权重去动态的改变感受野来估计运动模糊核；
-   对于图像特征金字塔中不同分辨率大小的特征图，本文提出应当采用不同的模块来提取不同分辨率大小中的有利的特征信息；
-   本文采用了U-Net形状的网络结构，为了在保证模型轻量化的同时保证图像的恢复效果本文采用了一个轻量化CNN-Transformer块。

为了验证本文所提出的算法性能，本文对算法进行了两个方面的测试：一是图像去模糊测试；二是视觉里程计测试